{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import torch\n",
    "from torch_geometric.datasets import Reddit\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn.models import VGAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%\n",
    "dataset = Reddit(root=\"data/Reddit\")\n",
    "\n",
    "print(type(dataset))\n",
    "# %%\n",
    "data = dataset[0]\n",
    "\n",
    "print(data.num_nodes)\n",
    "print(data.keys())\n",
    "\n",
    "\n",
    "# data.edge_index is 2 by num_edges tensor \n",
    "# column = [i,j] means there is an edge from node i to node j\n",
    "# data.y is the labels \n",
    "#   - not predicting this label. can add as feature or ignore\n",
    "# data.x is n by d, where n is number of nodes and d is number of features\n",
    "\n",
    "# how are we using train, val, test split?\n",
    "\n",
    "# TODO: encode and decode data\n",
    "# TODO: make anomaly detector for data (missing/new edges, significantly different features)\n",
    "#       - sort all nodes, most to least likely to be anomaly?\n",
    "\n",
    "# TODO: \n",
    "\n",
    "\n",
    "# might be helpful: https://github.com/Flawless1202/VGAE_pyG/\n",
    "# also, the VGAE() class\n",
    "# https://github.com/DaehanKim/vgae_pytorch\n",
    "# https://antoniolonga.github.io/Pytorch_geometric_tutorials/posts/post6.html\n",
    "#%%\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "# GAN: https://github.com/hwwang55/GraphGAN\n",
    "# https://arxiv.org/abs/1711.08267\n",
    "# https://medium.com/@_psycoplankton/graphgan-generative-adversarial-networks-for-graphs-ff4584375a81\n",
    "\n",
    "\n",
    "\n",
    "def rank_anomalous(original_data, reconstructed_data):\n",
    "    \n",
    "    # score for a node: something like\n",
    "    # num new edges (or edge deletions) with that node + || original feature - reconstructed feature||\n",
    "    # or something\n",
    "    \n",
    "    scores = [0]*original_data.num_nodes\n",
    "    for i in range(original_data.num_nodes):\n",
    "        scores += norm of original_data[i]-reconstructed_data[i]\n",
    "    \n",
    "    del_edges = (original_data.edge_index setminus reconstructed_data.edge_index)\n",
    "    ins_edges = (reconstructed_data.edge_index setminus original_data.edge_index)\n",
    "    for edge in del_edges.union(ins_edges):\n",
    "        scores[edge[0]] += 1\n",
    "        scores[edge[1]] += 1\n",
    "    \n",
    "    indices = list(range(original_data.num_nodes))\n",
    "    indices.sort(key = lambda i: -scores[i])\n",
    "    return indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
