{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn.models import VGAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_geometric.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root=\"data/Cora\", name=\"Cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anomaly_injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2582,    0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n",
      "Resampling...\n"
     ]
    }
   ],
   "source": [
    "new_data, struct_anomalies = anomaly_injection.structurally_perturb(data, 5, 30)\n",
    "new_new_data, att_anomalies = anomaly_injection.attribute_perturb(new_data, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1518, 2323, 1679, 1954, 1111, 1010,  716,  664,  943, 1834,  665, 1266,\n",
       "        1440, 1566, 2696, 1710,  617,   97,  826, 2448,  516, 2474, 1199, 1251,\n",
       "          79, 1594,   69,  433, 1232,  339,  354, 1405, 1980, 1760, 1324,  779,\n",
       "        1909, 2221, 2104, 1515,  792,  378, 2220, 1692, 1387,  279, 1101,  601,\n",
       "         626, 1879, 1764, 1833,  595, 1605,  775,  866,   29,  519, 1416,   38,\n",
       "         611,  557, 1968, 2306,  146, 1963, 2296,  363, 1769,  210, 1598,   85,\n",
       "        1876, 1979, 1417,   84,  456, 2386,  281, 1576,  642,  603, 2638, 1647,\n",
       "         313, 1411, 1986,  518,  105, 2195,  631, 2677, 1002, 2010, 1795, 2215,\n",
       "        1613,  449, 2698, 2120, 2152, 2172, 2121, 2132, 1937, 1779,  732,  302,\n",
       "        1976, 2608, 1905, 1874, 1941,  543, 1072,  883, 1060, 2496, 1340, 2671,\n",
       "        1024, 2151, 1054, 1312, 1611, 1959,  613,  698, 1281, 1550, 1208, 2493,\n",
       "        1457,  519,  395,  451, 1299, 1427,  343, 1259,  445,  879, 1844,  441,\n",
       "        1559, 2147,  709, 1353,  523, 2092, 2556, 1174, 1353, 2082, 1009, 1200,\n",
       "        1852, 2559, 2471, 1758,  110, 2204, 2409, 1802,  943,  603,  804,  419,\n",
       "        2126, 1425,  421, 1517, 2683, 1907,   77, 1046, 1613, 1043, 1725, 1617,\n",
       "         363, 1900, 1404, 1692, 1817,  589, 2631, 2101,  161, 1762,  899,  600,\n",
       "         719,  643,  158,  896, 1325, 1923, 1836,  167,  888, 1444,  373, 2031,\n",
       "         823,  553,  405, 1125, 2145, 2133, 2078, 2346, 1760,  162, 1755, 1673,\n",
       "        2179, 2201,  131, 1069, 1791, 2526, 1716, 2135, 1380, 1103, 2056, 1614,\n",
       "        1516, 2435,  163, 1473, 2432, 2562,  123, 1857,  739, 1950, 1374,  784,\n",
       "        2258, 1104,  349,  293, 2297, 1490, 2152, 2330, 1797, 2119, 1486, 2104,\n",
       "         413,  557, 1204,  399, 1604, 2342,  170, 1676, 2281, 1137, 2467, 2672,\n",
       "        2687,  285,  187, 2557, 1250, 2624,  253, 1328, 1846, 1165, 1234,  476,\n",
       "         205, 2493, 1998,  942, 2266, 2021, 1026, 1090,  103, 2593, 1720, 1337,\n",
       "        1659, 1938,  150, 1991, 2041, 2583,  615, 1290, 1787,  751, 1400,  440])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat([struct_anomalies.flatten(), att_anomalies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch_geometric.datasets.planetoid.Planetoid'>\n",
      "2708\n",
      "['train_mask', 'y', 'val_mask', 'edge_index', 'test_mask', 'x']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(dataset))\n",
    "# %%\n",
    "data = dataset[0]\n",
    "\n",
    "print(data.num_nodes)\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 633, 1862, 2582,  ...,  598, 1473, 2706],\n",
       "        [   0,    0,    0,  ..., 2707, 2707, 2707]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VariationalGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 114615892])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 2\n",
    "num_features = dataset.num_features\n",
    "epochs = 300\n",
    "\n",
    "\n",
    "model = VGAE(VariationalGCNEncoder(num_features, out_channels))  # new line\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "x = data.x.to(device)\n",
    "\n",
    "train_edge_mask = data.train_mask[data.edge_index[0]] & data.train_mask[data.edge_index[1]]\n",
    "\n",
    "train_pos_edge_index = data.edge_index[:,train_edge_mask].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    \n",
    "    loss = loss + (1 / data.num_nodes) * model.kl_loss()  # new line\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/GAE1_experiment_'+'2d_100_epochs')\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    \n",
    "    writer.add_scalar('auc train',auc,epoch) # new line\n",
    "    writer.add_scalar('ap train',ap,epoch)   # new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "\n",
    "# data.edge_index is 2 by num_edges tensor \n",
    "# column = [i,j] means there is an edge from node i to node j\n",
    "# data.y is the labels \n",
    "#   - not predicting this label. can add as feature or ignore\n",
    "# data.x is n by d, where n is number of nodes and d is number of features\n",
    "\n",
    "# how are we using train, val, test split?\n",
    "\n",
    "# TODO: encode and decode data\n",
    "# TODO: make anomaly detector for data (missing/new edges, significantly different features)\n",
    "#       - sort all nodes, most to least likely to be anomaly?\n",
    "\n",
    "# TODO: \n",
    "\n",
    "\n",
    "# might be helpful: https://github.com/Flawless1202/VGAE_pyG/\n",
    "# also, the VGAE() class\n",
    "# https://github.com/DaehanKim/vgae_pytorch\n",
    "# https://antoniolonga.github.io/Pytorch_geometric_tutorials/posts/post6.html\n",
    "#%%\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "# GAN: https://github.com/hwwang55/GraphGAN\n",
    "# https://arxiv.org/abs/1711.08267\n",
    "# https://medium.com/@_psycoplankton/graphgan-generative-adversarial-networks-for-graphs-ff4584375a81\n",
    "\n",
    "\n",
    "\n",
    "def rank_anomalous(original_data, reconstructed_data):\n",
    "    \n",
    "    # score for a node: something like\n",
    "    # num new edges (or edge deletions) with that node + || original feature - reconstructed feature||\n",
    "    # or something\n",
    "    \n",
    "    scores = [0]*original_data.num_nodes\n",
    "    for i in range(original_data.num_nodes):\n",
    "        scores += norm of original_data[i]-reconstructed_data[i]\n",
    "    \n",
    "    del_edges = (original_data.edge_index setminus reconstructed_data.edge_index)\n",
    "    ins_edges = (reconstructed_data.edge_index setminus original_data.edge_index)\n",
    "    for edge in del_edges.union(ins_edges):\n",
    "        scores[edge[0]] += 1\n",
    "        scores[edge[1]] += 1\n",
    "    \n",
    "    indices = list(range(original_data.num_nodes))\n",
    "    indices.sort(key = lambda i: -scores[i])\n",
    "    return indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
